{
  "cells": [
    {
      "metadata": {
        "id": "90agSsYPXDKQ"
      },
      "cell_type": "markdown",
      "source": [
        "# ChatBot Using PyTorch\n",
        "\n",
        "<img src='https://github.com/taruntiwarihp/raw_images/blob/master/download.png?raw=true'>\n",
        "\n",
        "A chatbot is a software application used to conduct an on-line chat conversation via text or text-to-speech, in lieu of providing direct contact with a live human agent. A chatbot is a type of software that can automate conversations and interact with people through messaging platforms."
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-input": true,
        "id": "rV_aD88kXDKR"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "PD6BVcZoXDKR",
        "outputId": "12d734ee-f510-4a39-87e8-b1879a2c3779",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import json,urllib\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import random\n",
        "import re # Import re for entity extraction\n",
        "import time\n",
        "import datetime\n",
        "!pip install ipywidgets\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import json\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.4.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.27.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.14.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.23)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.10.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.2)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.11.1)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.2)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.9.0.20250822)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vBu542TiXDKR"
      },
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l3(out)\n",
        "        # no activation and no softmax\n",
        "        return out\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "3wksJxVOXDKS"
      },
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "def tokenize(sentence):\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stem(word):\n",
        "    return stemmer.stem(word.lower())\n",
        "\n",
        "def bag_of_words(tokenized_sentence, all_words):\n",
        "    \"\"\"\n",
        "    sentence = [\"hello, \"how\", \"are\", \"you\"]\n",
        "    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
        "    bag =   [0,     1,       0,   1,    0,      0,       0 ]\n",
        "    \"\"\"\n",
        "    tokenized_sentence = [stem(w) for w in tokenized_sentence]\n",
        "\n",
        "    bag = np.zeros(len(all_words), dtype = np.float32)\n",
        "    for idx, w in enumerate(all_words):\n",
        "        if w in tokenized_sentence:\n",
        "            bag[idx] = 1.0\n",
        "    return bag\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "w7iUIODdXDKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7546476b-b7fe-488b-e195-e55721a009a9"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "url = '/content/drive/MyDrive/chatbot_nlp/intents.json'\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "VP7nxxifXDKS",
        "outputId": "205f75d8-e101-4960-ded5-3b927749f5f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "import json, urllib\n",
        "with open(url, 'r') as f:\n",
        "    intents = json.load(f)\n",
        "\n",
        "\n",
        "all_words = []\n",
        "tags = []\n",
        "xy = []\n",
        "for intent in intents['intents']:\n",
        "    tag = intent['tag']\n",
        "    tags.append(tag)\n",
        "    for pattern in intent['patterns']:\n",
        "        w = tokenize(pattern)\n",
        "        all_words.extend(w)\n",
        "        xy.append((w, tag))\n",
        "\n",
        "ignore_words = ['?','!','.',',']\n",
        "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
        "all_words = sorted(set(all_words))\n",
        "tags  = sorted(set(tags))\n",
        "\n",
        "X_train  = []\n",
        "y_train = []\n",
        "for (pattern_sentence, tag) in xy:\n",
        "    bag = bag_of_words(pattern_sentence, all_words)\n",
        "    X_train.append(bag)\n",
        "\n",
        "    label = tags.index(tag)\n",
        "    y_train.append(label) # CrossEntropyLoss\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "class ChatDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.n_samples = len(X_train)\n",
        "        self.x_data = X_train\n",
        "        self.y_data = y_train\n",
        "\n",
        "    # dataset[idx]\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "# Hyper paramters\n",
        "batch_size = 8\n",
        "hidden_size = 8\n",
        "output_size = len(tags)\n",
        "input_size = len(X_train[0])\n",
        "learning_rate = 0.001\n",
        "num_epochs = 1000\n",
        "\n",
        "\n",
        "dataset = ChatDataset()\n",
        "train_loader = DataLoader(dataset = dataset, batch_size = batch_size,\n",
        "                        shuffle =True, num_workers=2)\n",
        "\n",
        "device  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, output_size)\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for (words, labels) in train_loader:\n",
        "        words = words.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(words)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # backward and optimizer step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch +1) % 100 == 0:\n",
        "        # f'epoch {epoch+1}/{num_epochs}, loss={loss.item():.4f}'\n",
        "        print(\"epoch {}/{}, loss={:.4f}.\".format(epoch+1,num_epochs,loss.item()))\n",
        "\n",
        "# print(f'Final loss, loss={loss.item():.4f}')\n",
        "print(\"Final Loss, loss{:.4f}\".format(loss.item()))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 100/1000, loss=0.8549.\n",
            "epoch 200/1000, loss=0.0528.\n",
            "epoch 300/1000, loss=0.0704.\n",
            "epoch 400/1000, loss=0.0079.\n",
            "epoch 500/1000, loss=0.0018.\n",
            "epoch 600/1000, loss=0.0015.\n",
            "epoch 700/1000, loss=0.0029.\n",
            "epoch 800/1000, loss=0.0006.\n",
            "epoch 900/1000, loss=0.0001.\n",
            "epoch 1000/1000, loss=0.0003.\n",
            "Final Loss, loss0.0003\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hH4rxN5ZXDKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbdab9eb-3734-4d8b-e332-75579110f26c"
      },
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"model_state\":model.state_dict(),\n",
        "    \"input_size\":input_size,\n",
        "    \"output_size\":output_size,\n",
        "    \"hiddent_size\": hidden_size,\n",
        "    \"all_words\":all_words,\n",
        "    \"tags\": tags\n",
        "}\n",
        "FILE = \"/content/drive/MyDrive/chatbot_nlp/data.pth\"\n",
        "torch.save(data, FILE)\n",
        "\n",
        "print(\"Traning complete. file saved to\",FILE)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traning complete. file saved to /content/drive/MyDrive/chatbot_nlp/data.pth\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hfxjioNsXDKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc08dbf4-d35f-4162-b637-c3fd1a60062c"
      },
      "cell_type": "code",
      "source": [
        "device  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "with open(url,'r') as f:\n",
        "  intents = json.load(f)\n",
        "\n",
        "\n",
        "FILE = \"/content/drive/MyDrive/chatbot_nlp/data.pth\"\n",
        "data = torch.load(FILE)\n",
        "\n",
        "input_size = data['input_size']\n",
        "hidden_size = data['hiddent_size']\n",
        "output_size = data['output_size']\n",
        "all_words = data['all_words']\n",
        "tags = data['tags']\n",
        "model_state = data['model_state']\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "model.load_state_dict(model_state)\n",
        "model.eval()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (l1): Linear(in_features=80, out_features=8, bias=True)\n",
              "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
              "  (l3): Linear(in_features=8, out_features=12, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "MdxyjrEeXDKT"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/chatbot_nlp/all_india_PO_list_without_APS_offices_ver2_lat_long.csv\")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "wrBTKm-6XDKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e98dd79-f8ae-466a-f7da-df8d230ffb3a"
      },
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['officename', 'pincode', 'officeType', 'Deliverystatus', 'divisionname',\n",
              "       'regionname', 'circlename', 'Taluk', 'Districtname', 'statename',\n",
              "       'Telephone', 'Related Suboffice', 'Related Headoffice', 'longitude',\n",
              "       'latitude'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "rWM5-uIDXDKT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f95d5394-801e-4830-99be-23c109495d14"
      },
      "cell_type": "code",
      "source": [
        "df = df[['officename','pincode']]\n",
        "df.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  officename  pincode\n",
              "0              Achalapur B.O   504273\n",
              "1                    Ada B.O   504293\n",
              "2                Adegaon B.O   504307\n",
              "3  Adilabad Collectorate S.O   504001\n",
              "4               Adilabad H.O   504001"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c5afdbc-1651-486b-8137-c56bd2e4a168\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>officename</th>\n",
              "      <th>pincode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Achalapur B.O</td>\n",
              "      <td>504273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ada B.O</td>\n",
              "      <td>504293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adegaon B.O</td>\n",
              "      <td>504307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Adilabad Collectorate S.O</td>\n",
              "      <td>504001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adilabad H.O</td>\n",
              "      <td>504001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c5afdbc-1651-486b-8137-c56bd2e4a168')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c5afdbc-1651-486b-8137-c56bd2e4a168 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c5afdbc-1651-486b-8137-c56bd2e4a168');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ae534572-c340-4d45-9b07-aaf80ca073f4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae534572-c340-4d45-9b07-aaf80ca073f4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ae534572-c340-4d45-9b07-aaf80ca073f4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "49sICuNMXDKT"
      },
      "cell_type": "code",
      "source": [
        "def callme():\n",
        "  po = {v: k for v, k in enumerate(pf)}\n",
        "  print(\"Debjit: Select your near Post Office \\n \")\n",
        "\n",
        "  for i,j in po.items():\n",
        "    print(i,j)\n",
        "\n",
        "  while True:\n",
        "    try:\n",
        "      sel = int(input(\"\\n Enter Number\"))\n",
        "      if sel in po:\n",
        "        break\n",
        "      else:\n",
        "        print(\"Invalid number. Please select a number from the list.\")\n",
        "    except ValueError:\n",
        "      print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "  print(\"\\n Debjit: You selected {} Post office. \\n\".format(po[sel]))\n",
        "\n",
        "  sen = input(\"Debjit: Enter another query \\n You: \")\n",
        "  return sen"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwCvq74jFnvr"
      },
      "source": [
        "\n",
        "\n",
        "url = '/content/drive/MyDrive/chatbot_nlp/intents.json'\n",
        "\n",
        "import json\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import numpy as np\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def tokenize(sentence):\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stem(word):\n",
        "    return stemmer.stem(word.lower())\n",
        "\n",
        "def bag_of_words(tokenized_sentence, all_words):\n",
        "    \"\"\"\n",
        "    sentence = [\"hello, \"how\", \"are\", \"you\"]\n",
        "    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
        "    bag =   [0,     1,       0,   1,    0,      0,       0 ]\n",
        "    \"\"\"\n",
        "    tokenized_sentence = [stem(w) for w in tokenized_sentence]\n",
        "\n",
        "    bag = np.zeros(len(all_words), dtype = np.float32)\n",
        "    for idx, w in enumerate(all_words):\n",
        "        if w in tokenized_sentence:\n",
        "            bag[idx] = 1.0\n",
        "    return bag\n",
        "\n",
        "with open(url, 'r') as f:\n",
        "    intents = json.load(f)\n",
        "\n",
        "all_words = []\n",
        "tags = []\n",
        "xy = []\n",
        "for intent in intents['intents']:\n",
        "    tag = intent['tag']\n",
        "    tags.append(tag)\n",
        "    for pattern in intent['patterns']:\n",
        "        w = tokenize(pattern)\n",
        "        all_words.extend(w)\n",
        "        xy.append((w, tag))\n",
        "\n",
        "ignore_words = ['?','!','.',',']\n",
        "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
        "all_words = sorted(set(all_words))\n",
        "tags  = sorted(set(tags))\n",
        "\n",
        "X_train  = []\n",
        "y_train = []\n",
        "for (pattern_sentence, tag) in xy:\n",
        "    bag = bag_of_words(pattern_sentence, all_words)\n",
        "    X_train.append(bag)\n",
        "\n",
        "    label = tags.index(tag)\n",
        "    y_train.append(label) # CrossEntropyLoss\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4vZQTZ4FrJJ"
      },
      "source": [
        "# Load intents and prepare data, including helper functions\n",
        "import json\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import numpy as np\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def tokenize(sentence):\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stem(word):\n",
        "    return stemmer.stem(word.lower())\n",
        "\n",
        "def bag_of_words(tokenized_sentence, all_words):\n",
        "    \"\"\"\n",
        "    sentence = [\"hello, \"how\", \"are\", \"you\"]\n",
        "    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
        "    bag =   [0,     1,       0,   1,    0,      0,       0 ]\n",
        "    \"\"\"\n",
        "    tokenized_sentence = [stem(w) for w in tokenized_sentence]\n",
        "\n",
        "    bag = np.zeros(len(all_words), dtype = np.float32)\n",
        "    for idx, w in enumerate(all_words):\n",
        "        if w in tokenized_sentence:\n",
        "            bag[idx] = 1.0\n",
        "    return bag\n",
        "\n",
        "url = '/content/drive/MyDrive/chatbot_nlp/intents.json'\n",
        "\n",
        "with open(url, 'r') as f:\n",
        "    intents = json.load(f)\n",
        "\n",
        "all_words = []\n",
        "tags = []\n",
        "xy = []\n",
        "for intent in intents['intents']:\n",
        "    tag = intent['tag']\n",
        "    tags.append(tag)\n",
        "    for pattern in intent['patterns']:\n",
        "        w = tokenize(pattern)\n",
        "        all_words.extend(w)\n",
        "        xy.append((w, tag))\n",
        "\n",
        "ignore_words = ['?','!','.',',']\n",
        "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
        "all_words = sorted(set(all_words))\n",
        "tags  = sorted(set(tags))\n",
        "\n",
        "X_train  = []\n",
        "y_train = []\n",
        "for (pattern_sentence, tag) in xy:\n",
        "    bag = bag_of_words(pattern_sentence, all_words)\n",
        "    X_train.append(bag)\n",
        "\n",
        "    label = tags.index(tag)\n",
        "    y_train.append(label) # CrossEntropyLoss\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01f99267",
        "outputId": "fe9cd12c-4fbf-481b-9d8a-490e5bb9ea05"
      },
      "source": [
        "import json\n",
        "\n",
        "url = '/content/drive/MyDrive/chatbot_nlp/intents.json'\n",
        "\n",
        "with open(url, 'r') as f:\n",
        "    intents = json.load(f)\n",
        "\n",
        "# Brainstorming additional patterns for existing intents:\n",
        "\n",
        "# greetings\n",
        "intents['intents'][0]['patterns'].extend([\n",
        "    \"hey there\",\n",
        "    \"good morning\",\n",
        "    \"good afternoon\",\n",
        "    \"good evening\",\n",
        "    \"how are you doing\"\n",
        "])\n",
        "\n",
        "# goodbye\n",
        "intents['intents'][1]['patterns'].extend([\n",
        "    \"bye bye\",\n",
        "    \"see ya\",\n",
        "    \"talk to you later\",\n",
        "    \"have a good day\"\n",
        "])\n",
        "\n",
        "# thanks\n",
        "intents['intents'][2]['patterns'].extend([\n",
        "    \"thank you very much\",\n",
        "    \"thanks a lot\",\n",
        "    \"appreciate it\"\n",
        "])\n",
        "\n",
        "# items\n",
        "intents['intents'][5]['patterns'].extend([\n",
        "    \"what products do you sell\",\n",
        "    \"what items are available\",\n",
        "    \"show me your catalog\",\n",
        "    \"what can I buy\"\n",
        "])\n",
        "\n",
        "# hours\n",
        "intents['intents'][6]['patterns'].extend([\n",
        "    \"what are your business hours\",\n",
        "    \"when are you open until\",\n",
        "    \"what time do you close\"\n",
        "])\n",
        "\n",
        "# order status\n",
        "intents['intents'][7]['patterns'].extend([\n",
        "    \"where is my order\",\n",
        "    \"track my package\",\n",
        "    \"what is the status of my shipment\"\n",
        "])\n",
        "\n",
        "# cancel order\n",
        "intents['intents'][8]['patterns'].extend([\n",
        "    \"I want to cancel my purchase\",\n",
        "    \"can I stop my order\"\n",
        "])\n",
        "\n",
        "# New Intent Categories and their patterns and responses:\n",
        "\n",
        "# Shipping Information\n",
        "intents['intents'].append({\n",
        "    \"tag\": \"shipping\",\n",
        "    \"patterns\": [\n",
        "        \"what are your shipping options\",\n",
        "        \"how much is shipping\",\n",
        "        \"do you offer free shipping\",\n",
        "        \"how long does shipping take\",\n",
        "        \"what shipping carriers do you use\"\n",
        "    ],\n",
        "    \"responses\": [\n",
        "        \"We offer standard and express shipping options. Shipping costs vary based on your location and the weight of your order.\",\n",
        "        \"Shipping times typically range from 3-7 business days for standard shipping.\",\n",
        "        \"Yes, we offer free standard shipping on orders over a certain amount.\",\n",
        "        \"We use multiple carriers including FedEx, UPS, and USPS.\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Payment Methods\n",
        "intents['intents'].append({\n",
        "    \"tag\": \"payment\",\n",
        "    \"patterns\": [\n",
        "        \"what payment methods do you accept\",\n",
        "        \"can I pay with PayPal\",\n",
        "        \"do you take debit cards\",\n",
        "        \"is it safe to pay online\"\n",
        "    ],\n",
        "    \"responses\": [\n",
        "        \"We accept major credit cards (Visa, Mastercard, American Express), PayPal, and debit cards.\",\n",
        "        \"Yes, we accept PayPal.\",\n",
        "        \"Yes, we take debit cards.\",\n",
        "        \"Yes, our online payment system is secure and encrypted.\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Returns and Refunds\n",
        "intents['intents'].append({\n",
        "    \"tag\": \"returns\",\n",
        "    \"patterns\": [\n",
        "        \"how do I return an item\",\n",
        "        \"what is your return policy\",\n",
        "        \"can I get a refund\",\n",
        "        \"how long do refunds take\"\n",
        "    ],\n",
        "    \"responses\": [\n",
        "        \"Please visit our returns page on our website for detailed instructions on how to return an item.\",\n",
        "        \"You can return most items within 30 days of purchase for a full refund.\",\n",
        "        \"Yes, you can get a refund if the item meets our return policy criteria.\",\n",
        "        \"Refunds are usually processed within 5-10 business days after we receive the returned item.\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Account Information\n",
        "intents['intents'].append({\n",
        "    \"tag\": \"account\",\n",
        "    \"patterns\": [\n",
        "        \"how do I create an account\",\n",
        "        \"I forgot my password\",\n",
        "        \"how do I update my account information\",\n",
        "        \"can I change my email address\"\n",
        "    ],\n",
        "    \"responses\": [\n",
        "        \"You can create an account by clicking on the 'Sign Up' link on our website.\",\n",
        "        \"Click on the 'Forgot Password' link on the login page to reset your password.\",\n",
        "        \"You can update your account information by logging into your account settings.\",\n",
        "        \"Yes, you can change your email address in your account settings.\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Product Availability\n",
        "intents['intents'].append({\n",
        "    \"tag\": \"availability\",\n",
        "    \"patterns\": [\n",
        "        \"is this item in stock\",\n",
        "        \"when will this be available again\",\n",
        "        \"do you have this in my size\",\n",
        "        \"is this product still available\"\n",
        "    ],\n",
        "    \"responses\": [\n",
        "        \"Please check the product page for real-time stock information.\",\n",
        "        \"If an item is out of stock, you can often sign up for notifications to be alerted when it's back.\",\n",
        "        \"Our product pages list the available sizes.\",\n",
        "        \"The product page will indicate if the product is still available.\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "\n",
        "print(\"Brainstorming and data generation complete. New patterns and intents added to the 'intents' dictionary.\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brainstorming and data generation complete. New patterns and intents added to the 'intents' dictionary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf093573",
        "outputId": "9e50a932-949c-47f3-c07e-3afc4d1e8cd9"
      },
      "source": [
        "print(\"Example of updated intents:\")\n",
        "print(json.dumps(intents['intents'][0], indent=4))\n",
        "print(json.dumps(intents['intents'][-1], indent=4))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example of updated intents:\n",
            "{\n",
            "    \"tag\": \"greeting\",\n",
            "    \"patterns\": [\n",
            "        \"Hi\",\n",
            "        \"How are you\",\n",
            "        \"Is anyone there?\",\n",
            "        \"Hello\",\n",
            "        \"Good day\",\n",
            "        \"Whats up\",\n",
            "        \"hey there\",\n",
            "        \"good morning\",\n",
            "        \"good afternoon\",\n",
            "        \"good evening\",\n",
            "        \"how are you doing\"\n",
            "    ],\n",
            "    \"responses\": [\n",
            "        \"Hello!\",\n",
            "        \"Hey :-)\",\n",
            "        \"Hi there, what can I do for you?\",\n",
            "        \"Hi there, how can I help?\"\n",
            "    ]\n",
            "}\n",
            "{\n",
            "    \"tag\": \"availability\",\n",
            "    \"patterns\": [\n",
            "        \"is this item in stock\",\n",
            "        \"when will this be available again\",\n",
            "        \"do you have this in my size\",\n",
            "        \"is this product still available\"\n",
            "    ],\n",
            "    \"responses\": [\n",
            "        \"Please check the product page for real-time stock information.\",\n",
            "        \"If an item is out of stock, you can often sign up for notifications to be alerted when it's back.\",\n",
            "        \"Our product pages list the available sizes.\",\n",
            "        \"The product page will indicate if the product is still available.\"\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f72547d",
        "outputId": "2f8b9936-f4a0-45c1-e44d-c49e4f1cd39c"
      },
      "source": [
        "updated_intents_file = '/content/drive/MyDrive/chatbot_nlp/intents_updated.json'\n",
        "\n",
        "with open(updated_intents_file, 'w') as f:\n",
        "    json.dump(intents, f, indent=4)\n",
        "\n",
        "print(f\"Updated intents data saved to {updated_intents_file}\")\n",
        "print(\"The 'intents' dictionary now contains the expanded dataset.\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated intents data saved to /content/drive/MyDrive/chatbot_nlp/intents_updated.json\n",
            "The 'intents' dictionary now contains the expanded dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "219ef2c5",
        "outputId": "a92c7324-3e8f-435d-9afe-d99d5d7ed135"
      },
      "source": [
        "url = '/content/drive/MyDrive/chatbot_nlp/intents_updated.json'\n",
        "\n",
        "with open(url, 'r') as f:\n",
        "    intents = json.load(f)\n",
        "\n",
        "all_words = []\n",
        "tags = []\n",
        "xy = []\n",
        "for intent in intents['intents']:\n",
        "    tag = intent['tag']\n",
        "    tags.append(tag)\n",
        "    for pattern in intent['patterns']:\n",
        "        w = tokenize(pattern)\n",
        "        all_words.extend(w)\n",
        "        xy.append((w, tag))\n",
        "\n",
        "ignore_words = ['?','!','.',',']\n",
        "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
        "all_words = sorted(set(all_words))\n",
        "tags  = sorted(set(tags))\n",
        "\n",
        "X_train  = []\n",
        "y_train = []\n",
        "for (pattern_sentence, tag) in xy:\n",
        "    bag = bag_of_words(pattern_sentence, all_words)\n",
        "    X_train.append(bag)\n",
        "\n",
        "    label = tags.index(tag)\n",
        "    y_train.append(label) # CrossEntropyLoss\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "print(\"Data loaded and processed for training.\")\n",
        "print(f\"Number of training samples: {len(X_train)}\")\n",
        "print(f\"Number of unique words: {len(all_words)}\")\n",
        "print(f\"Number of unique tags: {len(tags)}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded and processed for training.\n",
            "Number of training samples: 90\n",
            "Number of unique words: 134\n",
            "Number of unique tags: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "517d997a",
        "outputId": "278e1657-faf6-43c7-a091-76df738978c8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# Define the AdvancedChatbotModel class again as it's needed for loading the state dict\n",
        "class AdvancedChatbotModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, num_classes):\n",
        "        super(AdvancedChatbotModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        out, _ = self.lstm(embedded)\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Define the helper functions again\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def tokenize(sentence):\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stem(word):\n",
        "    return stemmer.stem(word.lower())\n",
        "\n",
        "# Need to re-load intents and process data to ensure 'all_words', 'tags', and 'xy' are correct\n",
        "url = '/content/drive/MyDrive/chatbot_nlp/intents_updated.json'\n",
        "\n",
        "with open(url, 'r') as f:\n",
        "    intents = json.load(f)\n",
        "\n",
        "all_words = []\n",
        "tags = []\n",
        "xy = []\n",
        "for intent in intents['intents']:\n",
        "    tag = intent['tag']\n",
        "    tags.append(tag)\n",
        "    for pattern in intent['patterns']:\n",
        "        w = tokenize(pattern)\n",
        "        all_words.extend(w)\n",
        "        xy.append((w, tag))\n",
        "\n",
        "ignore_words = ['?','!','.',',']\n",
        "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
        "all_words = sorted(set(all_words))\n",
        "tags  = sorted(set(tags))\n",
        "\n",
        "\n",
        "# Create word_to_index mapping and pad data for sequence model\n",
        "word_to_index = {word: i + 1 for i, word in enumerate(all_words)} # Shift indices by 1\n",
        "word_to_index['<pad>'] = 0 # Assign 0 to padding\n",
        "all_words_padded = ['<pad>'] + all_words # Update all_words list for saving\n",
        "\n",
        "max_sequence_length = max(len(tokenize(p)) for intent in intents['intents'] for p in intent['patterns'])\n",
        "\n",
        "X_train_indices = []\n",
        "y_train = []\n",
        "for (pattern_sentence, tag) in xy:\n",
        "     # Convert tokenized sentence to indices using the updated word_to_index mapping\n",
        "     indices = [word_to_index.get(stem(w), word_to_index['<pad>']) for w in pattern_sentence]\n",
        "\n",
        "     # Pad with the padding index\n",
        "     padded_indices = indices + [word_to_index['<pad>']] * (max_sequence_length - len(indices))\n",
        "     X_train_indices.append(padded_indices)\n",
        "\n",
        "     label = tags.index(tag)\n",
        "     y_train.append(label) # CrossEntropyLoss\n",
        "\n",
        "X_train_indices = np.array(X_train_indices)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "class ChatDatasetWithSequences(Dataset):\n",
        "    def __init__(self, X_indices, y_data):\n",
        "        self.n_samples = len(X_indices)\n",
        "        self.x_data = torch.tensor(X_indices, dtype=torch.long) # Use long for indices\n",
        "        self.y_data = torch.tensor(y_data, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "# Hyperparameters for the new model\n",
        "batch_size = 8 # Assuming batch_size is defined\n",
        "learning_rate = 0.001 # Assuming learning_rate is defined\n",
        "num_epochs = 1000 # Assuming num_epochs is defined\n",
        "\n",
        "vocab_size = len(all_words_padded) # Including padding index\n",
        "embedding_dim = 50 # Choose an appropriate embedding dimension\n",
        "hidden_size = 128 # Increase hidden size\n",
        "num_layers = 2 # Add multiple layers for LSTM/GRU\n",
        "output_size = len(tags) # Number of intents\n",
        "\n",
        "\n",
        "# Re-instantiate DataLoader with the new dataset\n",
        "dataset_sequences = ChatDatasetWithSequences(X_train_indices, y_train)\n",
        "train_loader_sequences = DataLoader(dataset = dataset_sequences, batch_size = batch_size,\n",
        "                                    shuffle =True, num_workers=2)\n",
        "\n",
        "# Instantiate the new model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = AdvancedChatbotModel(vocab_size, embedding_dim, hidden_size, num_layers, output_size).to(device)\n",
        "\n",
        "# Use the same loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# Retrain the model\n",
        "print(\"\\nStarting training with the new model architecture...\")\n",
        "for epoch in range(num_epochs):\n",
        "    for (words_indices, labels) in train_loader_sequences:\n",
        "        words_indices = words_indices.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(words_indices)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # backward and optimizer step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch +1) % 100 == 0:\n",
        "        print(\"epoch {}/{}, loss={:.4f}.\".format(epoch+1,num_epochs,loss.item()))\n",
        "\n",
        "print(\"Training complete with the new model.\")\n",
        "\n",
        "# Update the data dictionary for saving the new model\n",
        "data = {\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"vocab_size\": vocab_size, # Input size is now vocab size for embedding layer\n",
        "    \"embedding_dim\": embedding_dim,\n",
        "    \"hidden_size\": hidden_size, # Corrected typo\n",
        "    \"num_layers\": num_layers,\n",
        "    \"output_size\": output_size,\n",
        "    \"all_words\": all_words_padded, # Save updated all_words with padding\n",
        "    \"tags\": tags,\n",
        "    \"max_sequence_length\": max_sequence_length, # Save max sequence length for inference\n",
        "    \"word_to_index\": word_to_index # Save word_to_index mapping\n",
        "}\n",
        "FILE = \"/content/drive/MyDrive/chatbot_nlp/data_advanced.pth\" # Save to a new file\n",
        "torch.save(data, FILE)\n",
        "\n",
        "print(\"Training complete. Advanced model file saved to\", FILE)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training with the new model architecture...\n",
            "epoch 100/1000, loss=0.0036.\n",
            "epoch 200/1000, loss=0.0004.\n",
            "epoch 300/1000, loss=0.0002.\n",
            "epoch 400/1000, loss=0.0002.\n",
            "epoch 500/1000, loss=0.0001.\n",
            "epoch 600/1000, loss=0.0001.\n",
            "epoch 700/1000, loss=0.0000.\n",
            "epoch 800/1000, loss=0.0000.\n",
            "epoch 900/1000, loss=0.0000.\n",
            "epoch 1000/1000, loss=0.4139.\n",
            "Training complete with the new model.\n",
            "Training complete. Advanced model file saved to /content/drive/MyDrive/chatbot_nlp/data_advanced.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17694e4b",
        "outputId": "9c336545-b92b-4cdb-935f-93f1a3394f07"
      },
      "source": [
        "import re\n",
        "\n",
        "def extract_entities(query):\n",
        "    \"\"\"\n",
        "    Extracts key entities (pincode, potential product names) from a user query.\n",
        "\n",
        "    Args:\n",
        "        query: The user's input query string.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the extracted entities.\n",
        "    \"\"\"\n",
        "    entities = {}\n",
        "\n",
        "    # Extract pincode: sequences of 6 digits\n",
        "    pincode_match = re.search(r'\\b(\\d{6})\\b', query)\n",
        "    if pincode_match:\n",
        "        entities['pincode'] = pincode_match.group(1)\n",
        "\n",
        "    potential_products = []\n",
        "    words = query.split()\n",
        "    for i, word in enumerate(words):\n",
        "        # Simple rule: capitalized word, not at the beginning of the sentence unless it's the only word\n",
        "        if word[0].isupper() and len(word) > 1 and (i > 0 or len(words) == 1):\n",
        "             # Exclude common capitalized words that are unlikely product names (e.g., \"I\", start of sentence words)\n",
        "             if word.lower() not in ['i', 'the', 'a', 'an', 'is', 'what', 'where', 'how', 'can', 'do', 'tell', 'me']:\n",
        "                # Consider multi-word product names (basic)\n",
        "                product_name = word\n",
        "                j = i + 1\n",
        "                while j < len(words) and words[j][0].isupper():\n",
        "                    product_name += \" \" + words[j]\n",
        "                    j += 1\n",
        "                potential_products.append(product_name)\n",
        "\n",
        "\n",
        "    # Another simple rule: look for words following \"about the\", \"info on\", etc.\n",
        "    query_lower = query.lower()\n",
        "    product_precursors = [\"about the \", \"info on the \", \"details about \", \"price of the \"]\n",
        "    for precursor in product_precursors:\n",
        "        match = re.search(re.escape(precursor) + r'(\\w+)', query_lower)\n",
        "        if match:\n",
        "            potential_products.append(match.group(1).capitalize()) # Capitalize for consistency\n",
        "\n",
        "    # Remove duplicates and add to entities, prioritize longer matches if any overlap\n",
        "    if potential_products:\n",
        "         # Simple deduplication and selection (could be improved)\n",
        "        entities['product'] = list(set(potential_products)) # Store as a list for now\n",
        "\n",
        "    return entities\n",
        "\n",
        "# Example Usage:\n",
        "test_queries = [\n",
        "    \"What is the status of my order with pincode 700099?\",\n",
        "    \"Tell me about the Laptop\",\n",
        "    \"Do you have the Red Shoes?\",\n",
        "    \"I need information on the Bluetooth Speaker\",\n",
        "    \"What is the price of the Big Screen TV?\",\n",
        "    \"Hello, what items do you have?\",\n",
        "    \"My pincode is 110001.\",\n",
        "    \"How do I return the Defective Product?\",\n",
        "    \"Just a general query.\"\n",
        "]\n",
        "\n",
        "print(\"Testing entity extraction:\")\n",
        "for query in test_queries:\n",
        "    extracted = extract_entities(query)\n",
        "    print(f\"Query: '{query}'\")\n",
        "    print(f\"Extracted Entities: {extracted}\")\n",
        "    print(\"-\" * 20)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing entity extraction:\n",
            "Query: 'What is the status of my order with pincode 700099?'\n",
            "Extracted Entities: {'pincode': '700099'}\n",
            "--------------------\n",
            "Query: 'Tell me about the Laptop'\n",
            "Extracted Entities: {'product': ['Laptop']}\n",
            "--------------------\n",
            "Query: 'Do you have the Red Shoes?'\n",
            "Extracted Entities: {'product': ['Red Shoes?', 'Shoes?']}\n",
            "--------------------\n",
            "Query: 'I need information on the Bluetooth Speaker'\n",
            "Extracted Entities: {'product': ['Bluetooth Speaker', 'Speaker']}\n",
            "--------------------\n",
            "Query: 'What is the price of the Big Screen TV?'\n",
            "Extracted Entities: {'product': ['Screen TV?', 'Big', 'TV?', 'Big Screen TV?']}\n",
            "--------------------\n",
            "Query: 'Hello, what items do you have?'\n",
            "Extracted Entities: {}\n",
            "--------------------\n",
            "Query: 'My pincode is 110001.'\n",
            "Extracted Entities: {'pincode': '110001'}\n",
            "--------------------\n",
            "Query: 'How do I return the Defective Product?'\n",
            "Extracted Entities: {'product': ['Defective Product?', 'Product?']}\n",
            "--------------------\n",
            "Query: 'Just a general query.'\n",
            "Extracted Entities: {}\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "3e1b2971c8544d4c823073dea1f68a77",
            "bb7afebc02f44549bd84e72a39c90716",
            "9c26dd20e208422f9391b25e457a1cd6",
            "68ed502588994bd5b81f45890a658019",
            "557fea4ebcc84cb184979de7cb613020",
            "2e977b55dcbe4614beecc457dd40b09d",
            "8e8d2670d7a2484eb46372d98e634b72",
            "9f513070a27745f59e58dfa975101c47"
          ]
        },
        "id": "df501f1e",
        "outputId": "e4d50b29-9d53-4d14-da75-ed1e6f489e5f"
      },
      "source": [
        "# Create input and output widgets\n",
        "input_box = widgets.Text(placeholder='Enter your message here...')\n",
        "output_area = widgets.Output()\n",
        "\n",
        "# Function to handle button click and process input\n",
        "def on_send_button_clicked(b):\n",
        "    with output_area:\n",
        "        clear_output() # Clear previous output\n",
        "        user_message = input_box.value\n",
        "        print(f\"You: {user_message}\")\n",
        "        input_box.value = \"\" # Clear the input box\n",
        "\n",
        "        if user_message.lower() == 'quit':\n",
        "            print(f\"{bot_name}: Goodbye!\")\n",
        "            # Consider stopping the interaction here in a more robust UI\n",
        "            return\n",
        "\n",
        "        # --- Chatbot Logic (Adapted from the main loop) ---\n",
        "        response_text = \"\"\n",
        "\n",
        "        # Call the extract_entities function on raw user input\n",
        "        extracted_entities = extract_entities(user_message)\n",
        "\n",
        "        # Check if a pincode was extracted\n",
        "        pincode_handled = False\n",
        "        if 'pincode' in extracted_entities:\n",
        "            try:\n",
        "                pincode = int(extracted_entities['pincode'])\n",
        "                # Use the globally loaded pincode dataframe (assuming df is loaded)\n",
        "                if 'df' in globals():\n",
        "                    pf = list(df['officename'][df['pincode'] == pincode ])\n",
        "                    if len(pf) == 0:\n",
        "                        response_text = f\"{bot_name} : Sorry to inform you, We don't deliver here :(\"\n",
        "                    else:\n",
        "                        response_text = f\"{bot_name} : Here are the post offices for pincode {pincode}:\\n\"\n",
        "                        po = {v: k for v, k in enumerate(pf)}\n",
        "                        for i, j in po.items():\n",
        "                            response_text += f\"{i}: {j}\\n\"\n",
        "                        response_text += \"\\nDebjit: Enter another query\" # Suggest next step\n",
        "                else:\n",
        "                    response_text = f\"{bot_name} : Pincode data not loaded. Please run the data loading cell.\"\n",
        "\n",
        "                pincode_handled = True\n",
        "            except ValueError:\n",
        "                 response_text = f\"{bot_name} : Invalid pincode format detected.\"\n",
        "                 pincode_handled = True\n",
        "\n",
        "        if not pincode_handled:\n",
        "\n",
        "            if all(v in globals() for v in ['all_words_padded', 'word_to_index', 'max_sequence_length', 'model', 'tags', 'device']):\n",
        "                tokenized_sentence = tokenize(user_message)\n",
        "                sentence_indices = [word_to_index.get(stem(word), word_to_index.get('<pad>', 0)) for word in tokenized_sentence] # Use .get with default for safety\n",
        "                padded_sentence_indices = sentence_indices + [word_to_index.get('<pad>', 0)] * (max_sequence_length - len(sentence_indices))\n",
        "                padded_sentence_indices = padded_sentence_indices[:max_sequence_length]\n",
        "\n",
        "                X = torch.tensor(padded_sentence_indices, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "                outputs = model(X)\n",
        "                _, predicted = torch.max(outputs, dim=1)\n",
        "                tag = tags[predicted.item()]\n",
        "\n",
        "                probs = torch.softmax(outputs, dim=1)\n",
        "                prob = probs[0][predicted.item()]\n",
        "\n",
        "                if prob.item() > 0.75: # Confidence threshold\n",
        "                    for intent_data in intents[\"intents\"]: # Ensure intents is loaded\n",
        "                        if tag == intent_data[\"tag\"]:\n",
        "                            # Handle product information requests using the mock API\n",
        "                            if tag == \"items\" and 'product' in extracted_entities and extracted_entities['product']:\n",
        "                                product_name = extracted_entities['product'][0]\n",
        "                                product_details = get_product_info_from_mock_api(product_name) # Ensure this function is defined\n",
        "\n",
        "                                if product_details:\n",
        "                                     response_text = f\"{bot_name} : Here is the information for {product_name}: Price - {product_details['price']}, Availability - {product_details['availability']}, Features - {product_details['features']}.\"\n",
        "                                else:\n",
        "                                     response_text = f\"{bot_name} : Sorry, I couldn't find information for '{product_name}'. Is there anything else I can help with regarding items?\"\n",
        "\n",
        "                            else:\n",
        "                                 # If no specific entity-based response, use a random pre-defined response\n",
        "                                 response_text = f\"{bot_name} : {random.choice(intent_data['responses'])}\"\n",
        "\n",
        "                else:\n",
        "                    # Handle out-of-scope queries\n",
        "                    response_text = f\"{bot_name} I do not understand...contact on WhatsApp 1234567890\"\n",
        "            else:\n",
        "                 response_text = f\"{bot_name}: Chatbot components not fully loaded. Please run the necessary setup cells.\"\n",
        "\n",
        "        # --- End Chatbot Logic ---\n",
        "\n",
        "        if response_text:\n",
        "             print(response_text)\n",
        "\n",
        "\n",
        "# Create a send button\n",
        "send_button = widgets.Button(description=\"Send\")\n",
        "\n",
        "# Link the button click to the function\n",
        "send_button.on_click(on_send_button_clicked)\n",
        "\n",
        "# Display the input box, send button, and output area\n",
        "print(\"Namste !!! We are working everywhere in Pan-india. Just drop you delivery location pincode/postal code to check delivery availability or ask us at Whatsapp Helpline 1234567890.\")\n",
        "display(input_box, send_button, output_area)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namste !!! We are working everywhere in Pan-india. Just drop you delivery location pincode/postal code to check delivery availability or ask us at Whatsapp Helpline 1234567890.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', placeholder='Enter your message here...')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e1b2971c8544d4c823073dea1f68a77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Send', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68ed502588994bd5b81f45890a658019"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e8d2670d7a2484eb46372d98e634b72"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57b91544"
      },
      "source": [
        "## Sample Queries to Test the Chatbot\n",
        "\n",
        "You can use these sample queries to interact with the chatbot and see how it responds based on the implemented advanced NLP techniques, entity extraction, and mock API integration.\n",
        "\n",
        "**General Interactions:**\n",
        "- Hello\n",
        "- How are you?\n",
        "- Thanks\n",
        "- Bye\n",
        "\n",
        "**Pincode Lookup:**\n",
        "- My pincode is 700099\n",
        "- What post offices are in 110001?\n",
        "- Check delivery for pincode 504001\n",
        "\n",
        "**Product Information (Mock API):**\n",
        "- Tell me about the Laptop\n",
        "- What is the price of the keyboard?\n",
        "- Is the monitor in stock?\n",
        "- Do you have the webcam?\n",
        "\n",
        "**New Intents:**\n",
        "- What payment methods do you accept? (Payment)\n",
        "- How much is shipping? (Shipping)\n",
        "- What is your return policy? (Returns and Refunds)\n",
        "- How do I create an account? (Account Information)\n",
        "- Is this item in stock? (Product Availability - general)\n",
        "\n",
        "**Out-of-Scope Query:**\n",
        "- Tell me about the weather today.\n",
        "- What is the capital of France?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e1b2971c8544d4c823073dea1f68a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_bb7afebc02f44549bd84e72a39c90716",
            "placeholder": "Enter your message here...",
            "style": "IPY_MODEL_9c26dd20e208422f9391b25e457a1cd6",
            "value": ""
          }
        },
        "bb7afebc02f44549bd84e72a39c90716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c26dd20e208422f9391b25e457a1cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68ed502588994bd5b81f45890a658019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Send",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_557fea4ebcc84cb184979de7cb613020",
            "style": "IPY_MODEL_2e977b55dcbe4614beecc457dd40b09d",
            "tooltip": ""
          }
        },
        "557fea4ebcc84cb184979de7cb613020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e977b55dcbe4614beecc457dd40b09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "8e8d2670d7a2484eb46372d98e634b72": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9f513070a27745f59e58dfa975101c47",
            "msg_id": "",
            "outputs": []
          }
        },
        "9f513070a27745f59e58dfa975101c47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}